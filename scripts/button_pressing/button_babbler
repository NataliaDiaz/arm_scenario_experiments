#!/usr/bin/env python
''' This script controls baxter by randomly choosing position for the left-limb end effector and using the Inverse Kinematic service (hence IK) to reach this point.

The script also controls what is recorded, so that a snapshot of the world is recorded after every 3D position of the end-effector is reached (and nothing is recording in between)
This is usefull as the recorded messages are already corresponding to states between 2 actions hae been chosen. 
If permanent recording had been used instead, it would have been harder (while using the data) to pick up the states corresponding to moments between two actions.
'''

import math
import random
import argparse

import rospy
from tf import transformations
np = transformations.numpy
quat_conj = transformations.quaternion_conjugate
from geometry_msgs.msg import Point, Quaternion, Vector3, Vector3Stamped
from std_msgs.msg import Header
import baxter_interface
import arm_scenario_simulator as arm_sim
from arm_scenario_experiments import Recorder, utils, baxter_utils

# ['left_e0', 'left_e1', 'left_s0', 'left_s1', 'left_w0', 'left_w1', 'left_w2']
IK_seed_positions = [-1.535, 1.491, -0.038, 0.194, 1.546, 1.497, -0.520]


def main(path):
    limb = baxter_interface.Limb('left')
    ee_orientation = baxter_utils.get_ee_orientation(limb)

    # those are publishers specially made to be listenned by the recorder, so that we can publish and thus record exactly what we want when we want
    action_pub = rospy.Publisher('/robot/limb/left/endpoint_action', Vector3Stamped, queue_size=1)
    button_pos_pub = rospy.Publisher('/button1/position', Point, queue_size=1)
    
    # here we define what topics the recorder will listen to (which is necessary to be able to record some message from them)
    recorder = Recorder(path, prefix='/recorded', topics = [ '/cameras/head_camera_2/image/compressed', 
                                                            '/robot/joint_states',
                                                            '/robot/limb/left/endpoint_state',  
                                                            '/robot/limb/left/endpoint_action', 
                                                            '/button1/is_pressed', 
                                                            '/button1/position'])

    def wait_for_messages(excepts=[]):
        while not recorder.all_buffers_full(excepts=excepts): 
            print('waiting')
            rospy.sleep(0.01) 
 
    # Here we define some parameters for he babbling
    delta = 0.05
    possible_deltas = [i*delta for i in xrange(-1,2)]
    mins = np.array([0.35, -0.05, -0.14+delta])
    maxs = mins + delta*np.array([10, 14, 12])
    nexpert, nrandom = 20, 20
    nstep = 50000

    button = arm_sim.Button('button1')
    button_orientation = button.get_state().pose.orientation
    baxter = arm_sim.Button('baxter')
    baxter_pose = baxter.get_state().pose
    baxter_position = utils.point2array(baxter_pose.position)
    baxter_orientation = utils.quat2array(baxter_pose.orientation)

    # this is the expert controller. Given the actual position of the ee, it gives the optimal action to perform to get closer to the button
    def action_to_goal(end_point_position, button_pos_relative):
        return np.sign(button_pos_relative-end_point_position)*delta

    def reset_button(button_pos_absolute):
        if np.linalg.norm(button_pos_absolute-utils.point2array(button.get_state().pose.position))>0.01: 
            button.set_state(position = Point(*button_pos_absolute), orientation = button_orientation)

    # Function that randomly put the button on the table (useful to initialize a new sequence)
    def move_button():
        new_position = np.random.uniform(mins,maxs)
        new_position[2] = -0.16
        button.set_state( Point(*utils.change_CS(new_position, -baxter_position, quat_conj(baxter_orientation)) ), orientation = button_orientation )
        button_pos_absolute = utils.point2array( button.get_state().pose.position )
        button_pos_relative = utils.change_CS( button_pos_absolute, baxter_position, baxter_orientation)
        button_pos_pub.publish( Point(*button_pos_relative) )
        return button_pos_relative, button_pos_absolute

    def move_limb_to_init():   
        position = np.random.uniform(mins,maxs)
        position[2] = mins[2] + 8*delta
        joints = baxter_utils.IK(limb, position, ee_orientation, IK_seed_positions)   
        limb.move_to_joint_positions(joints)
        return position

    # Actually starts the babbling
    for nb_button_pos in range(1):        
        recorder.new_bag('record_'+str(nb_button_pos))
        end_point_position = move_limb_to_init()
        button_pos_relative, button_pos_absolute = move_button()

        k, k_success = 0, 0
        recently_pressed = False
        expert_control = False
        buffer_action = []
        while k_success<nstep and k<nstep*1.2:
            k = k+1
            actual_mins = np.array(mins)
            if np.linalg.norm(button_pos_relative[0:2]-utils.point2array(limb.endpoint_pose()['position'])[0:2])<=delta: 
                actual_mins[2] -= delta

            if button.is_pressed():
                buffer_action = [np.concatenate((np.random.choice(possible_deltas,2),[delta])) for _ in xrange(6)]
                recently_pressed = True
                expert_control = False
            elif not buffer_action:
                if nrandom<k_success%(nexpert+nrandom): 
                    expert_control = not recently_pressed
                else: 
                    recently_pressed = False
                    expert_control = False

                if expert_control:
                    buffer_action.append( action_to_goal(end_point_position, button_pos_relative) )
                else:
                    buffer_action.append( np.random.choice(possible_deltas,3) )  

            action = buffer_action.pop(0)
            end_point_position_candidate = (end_point_position+action).clip(actual_mins, maxs)
            action = end_point_position_candidate - end_point_position
            joints = baxter_utils.IK(limb, end_point_position_candidate,  ee_orientation)
            if joints:
                action_pub.publish( Vector3Stamped(Header(stamp=rospy.Time.now()), Vector3(*action)) )
                end_point_position = end_point_position_candidate
                k_success +=1
                reset_button(button_pos_absolute)
                wait_for_messages(excepts=['/button1/position'])
                recorder.dump_all()
                limb.move_to_joint_positions(joints, timeout = 3)
                reset_button(button_pos_absolute)

        wait_for_messages(excepts=['/button1/position','/robot/limb/left/endpoint_action'])
        recorder.dump_all()
        recorder.close_bag()      


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('path', type=str, help="path to bag file in which data will be recorded")
    args = parser.parse_args(rospy.myargv()[1:])

    print("Initializing babbler node... ")
    rospy.init_node("learning_to_press_node")
    print("Getting robot state... ")
    rs = baxter_interface.RobotEnable(baxter_interface.CHECK_VERSION)
    print("Enabling robot... ")
    rs.enable()
    print("Running. Ctrl-c to quit")
    try: main(args.path)
    except rospy.ROSInterruptException:  pass
